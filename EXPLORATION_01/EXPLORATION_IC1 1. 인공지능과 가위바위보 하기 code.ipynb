{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "seeing-collective",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os, glob\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-variation",
   "metadata": {},
   "source": [
    "업로드 된 가위 바위 보 훈련 이미지 리사이즈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "presidential-prototype",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  images to be resized.\n",
      "0  images resized.\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "imported-probe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400  images to be resized.\n",
      "400  images resized.\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "surface-relaxation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400  images to be resized.\n",
      "400  images resized.\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greek-brown",
   "metadata": {},
   "source": [
    "라벨링 및 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "molecular-diesel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 1200 입니다.\n",
      "x_train shape: (1200, 28, 28, 3)\n",
      "y_train shape: (1200,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number_of_data=1200):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train_norm.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-joshua",
   "metadata": {},
   "source": [
    "이미지 불러서 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "computational-equation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[433])\n",
    "print('라벨: ', y_train[433])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spread-adobe",
   "metadata": {},
   "source": [
    "# 딥러닝 네트워크 설계하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "protected-ivory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 31,050\n",
      "Trainable params: 31,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "undefined-hudson",
   "metadata": {},
   "source": [
    "# 딥러닝 네트워크 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "planned-legislature",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "38/38 [==============================] - 5s 49ms/step - loss: 1.7856 - accuracy: 0.3292\n",
      "Epoch 2/20\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.1161 - accuracy: 0.3528\n",
      "Epoch 3/20\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.0376 - accuracy: 0.5186\n",
      "Epoch 4/20\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9584 - accuracy: 0.5709\n",
      "Epoch 5/20\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8332 - accuracy: 0.6606\n",
      "Epoch 6/20\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.7438 - accuracy: 0.7123\n",
      "Epoch 7/20\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6146 - accuracy: 0.7817\n",
      "Epoch 8/20\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5578 - accuracy: 0.7874\n",
      "Epoch 9/20\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5556 - accuracy: 0.7866\n",
      "Epoch 10/20\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4651 - accuracy: 0.8457\n",
      "Epoch 11/20\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4141 - accuracy: 0.8796\n",
      "Epoch 12/20\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3576 - accuracy: 0.8878\n",
      "Epoch 13/20\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3086 - accuracy: 0.9163\n",
      "Epoch 14/20\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2928 - accuracy: 0.9255\n",
      "Epoch 15/20\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2656 - accuracy: 0.9137\n",
      "Epoch 16/20\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2451 - accuracy: 0.9345\n",
      "Epoch 17/20\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2142 - accuracy: 0.9269\n",
      "Epoch 18/20\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2053 - accuracy: 0.9467\n",
      "Epoch 19/20\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2044 - accuracy: 0.9354\n",
      "Epoch 20/20\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1872 - accuracy: 0.9452\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff4d7e0d750>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.compile()과 model.fit()을 사용해 봅시다.\n",
    "# [[YOUR CODE]]\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informed-aspect",
   "metadata": {},
   "source": [
    "# 얼마나 잘 만들었는지 확인하기(테스트)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "interim-witch",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471  images to be resized.\n",
      "471  images resized.\n",
      "테스트 이미지 resize 완료!\n",
      "학습데이터(x_train)의 이미지 개수는 471 입니다.\n",
      "x_train shape: (1200, 28, 28, 3)\n",
      "y_train shape: (1200,)\n"
     ]
    }
   ],
   "source": [
    "# x_test, y_test를 만드는 방법은 x_train, y_train을 만드는 방법과 아주 유사합니다.\n",
    "# [[YOUR CODE_리사이즈]]\n",
    "import os\n",
    "\n",
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/*\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"테스트 이미지 resize 완료!\")\n",
    "\n",
    "# [[YOUR CODE]]\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
    "(x_test, y_test)=load_data(image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_test_norm.shape))\n",
    "print(\"y_train shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "described-netherlands",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 - 0s - loss: 1.4027 - accuracy: 0.2125\n",
      "test_loss: 1.402746319770813 \n",
      "test_accuracy: 0.21250000596046448\n"
     ]
    }
   ],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.evaluate()을 사용해 봅시다.\n",
    "# [[YOUR CODE]]\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-webmaster",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
